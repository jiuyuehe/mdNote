dfs
---
>分布式文件系统（Distributed File System）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点相连，也就是集群文件系统，可以支持大数量的节点以及PB级的数量存储


tfs
---

>**淘宝开源的分布式文件系统**
>
*  TFS为淘宝提供海量小文件存储，通常文件大小不超过1M，满足了淘宝对小文件存储的需求
*  HA架构
*  同时扁平化的数据组织结构，可将文件名映射到文件的物理地址，简化了文件的访问流程，一定程度上为TFS提供了良好的读写性能。


>** tfs 整体结构**
>
* **一个tfs集群**  =  2个!NameServer(一主一备) 多个！dataServer.可以简单的看做 2个master 多个slaver.
* **Block**:  (块) 由多个小文件合并成1个大文件，在集群里面有唯一的编号（BlockId）这个编号由master 分配 ，同时master 维护blockId和slaver.Block中的实际数据都存在slaver上。
* **master** : 管理维护Block和!DataServer相关信息,包括!DataServer加入，退出, 心跳信息, block和!DataServer的对应关系建立，解除。简单的说：一个block会存在一个slaver上，master负责创建，删除，复制，均衡，整理，master不负责数据的读写，而是交由slaver完成。
* **slaver** : 主要负责读写，存储。
* [结构图](http://code.taobao.org/p/tfs/file/305/structure.png)
* **容灾**：master HA架构，slaver 容错，整套tfs 的双重热备方案。
* **TFS 文件格式**：[tfs文件格式图](http://code.taobao.org/p/tfs/file/309/filename.png)
>
**扩容**
>
* 原有TFS集群运行一定时间后，集群容量不足，此时需要对TFS集群扩容。由于DataServer与NameServer之间使用心跳机制通信，如果系统扩容，只需要将相应数量的新!DataServer服务器部署好应用程序后启动即可。这些!DataServer服务器会向!NameServer进行心跳汇报。!NameServer会根据!DataServer容量的比率和!DataServer的负载决定新数据写往哪台!DataServer的服务器。根据写入策略，容量较小，负载较轻的服务器新数据写入的概率会比较高。同时，在集群负载比较轻的时候，!NameServer会对!DataServer上的Block进行均衡，使所有!DataServer的容量尽早达到均衡。
由于tfs 安装需要数十个插件，部署难度打， 安装失败！ 
------

nginx + gridfs +mongodb 实现分布式文件系统。
---
#### mongodb introduces ####
* Mongo是一个高性能，开源，无模式的文档型数据库，它在许多场景下可用于替代传统的关系型数据库或键/值存储方式。Mongo使用C++开发，提供了以下功能： 


* 面向集合的存储：适合存储对象及JSON形式的数据。 
* 动态查询：Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。 
* 完整的索引支持：包括文档内嵌对象及数组。Mongo的查询优化器会分析查询表达式，并生成一个高效的查询计划。 
* 查询监视：Mongo包含一个监视工具用于分析数据库操作的性能。 
* 复制及自动故障转移：Mongo数据库支持服务器之间的数据复制，支持主-从模式及服务器之间的相互复制。复制的主要目标是提供冗余及自动故障转移。 
* 高效的传统存储方式：支持二进制数据及大型对象（如照片或图片）**【国外有网站用来存储视频】**。 
* 自动分片以支持云级别的伸缩性：自动分片功能支持水平的数据库集群，可动态添加额外的机器。
* 丰富的资料[mogodb资料汇总](http://blog.nosqlfan.com/html/3548.html)


---------
基础篇
--------

mongodb 安装使用：
下载，解压，运行 
    `./mongod --dbpath=/opt/mongodb/dbdata --logpath=/opt/mongodb/log/mongo.log --fork`
	wget http://nginx.org/download/nginx-1.4.2.tar.gz

	准备： mongodb-linux-x86_64-2.4.5
	nginx-1.4.2
	nginx-gridfs

	./mongofiles put -d pics -type jpg 2.jpg
	mongofiles -d pics -l 'C:\Users\jiuyuehe\Desktop\socket.io-client-0.9.16.zip' put 'socket.io-client-0.9.16.zip'

---
复制集：
---

* root      1608     1  0 10:15 ?        00:00:06
  `./mongod --dbpath=/dfs/mongo/dbdata/ --port 17017 --logpath=/dfs/mongo/dblog/mongo1.log --fork --replSet oatos --directoryperdb`
* root      1668     1  0 10:17 ?        00:00:06 
  `./mongod --dbpath=/dfs/mongo_re/dbdata/ --port 17019 --logpath=/dfs/mongo_re/dblog/mongo_re1.log --fork --replSet oatos --directoryperdb`
* root      1719     1  0 10:18 ?        00:00:05 
	 `./mongod --dbpath=/dfs/mongo_arb/dbdata/ --port 17020 --logpath=/dfs/mongo_arb/dblog/mongo_ar1.log --fork --replSet oatos --directoryperdb`



* conf={_id:"oatos",members:[{_id:0,host:"192.168.1.54:17017",priority:4},{_id:1,host:"192.168.1.54:17019",priority:2},{_id:2,host:"192.168.1.54:17020",arbiterOnly:true}]}


*  rs.initiate(conf)


* rs.status()


----------------------
mongodb 分片存储
---
* ./mongod -dbpath=../../dbdata/ --logpath=../../dblog/mc.log --fork --port 27019
* ./mongos --configdb=127.0.0.1:27019 --logpath=../../dblog/mongos.log --fork
* ./mongo admin
* sh.addShard("oatos/192.168.1.54:17019,192.168.1.54:17017")
* sh.status()


>	sh.enableSharding("pics")
>	建立索引
	mongos db.users.ensureIndex({name:1})
	mongos db.users.getIndexes()
	将数据库按字段分片
	sh.shardCollection("pics.users",{"name":1})


-------------------
#### GridFS intro ####
>GridFS is a specification for storing and retrieving files that exceed the BSON-document size limit of 16MB.

>Instead of storing a file in a single document, GridFS divides a file into parts, or chunks, [1] and stores each of those chunks as a separate document. By default GridFS limits chunk size to 256k. GridFS uses two collections to store files. One collection stores the file chunks, and the other stores file metadata.

>When you query a GridFS store for a file, the driver or client will reassemble the chunks as needed. You can perform range queries on files stored through GridFS. You also can access information from arbitrary sections of files, which allows you to “skip” into the middle of a video or audio file.

>GridFS is useful not only for storing files that exceed 16MB but also for storing any files for which you want access without having to load the entire file into memory. For more information on the indications of GridFS, **see When should I use GridFS**

> 
*  gridfs 是一个归范用于存储和检索文件超过 标准为16m的bson 文档 。他将一个文件分成很多个块，每一个块的limits size 是256k。gridfs 使用用2个collections 来存储文件，一个存储file chunks，一个存储file metadata.
* 当你查询gridfs里面的文件时，客户端或者驱动将会装配你需要的chunks,你能使用区域查询，你也可以访问文件的任意部分，允许你跳到视频或者声音文件的任何地方。
* Gridfs 不但可以用来存储超过16m的文件，而且可以存储任何文件，并且不需要一次把整个文件加载到内存中。
* 更多详细信息请看下面

#### GridFS 的使用场景 ####

>#### When should I use GridFS? ####
For documents in a MongoDB collection, you should always use GridFS for storing files larger than 16 MB.
In some situations, storing large files may be more efficient in a MongoDB database than on a system-level filesystem.
>
* 在mongodb 的文档集中，你应当用gridFs来存储大于16M的文件，在一些情况下，会比文件系统存储大文件要好。 

>If your filesystem limits the number of files in a directory, you can use GridFS to store as many files as needed.
>
* 如果你的文件系统限制文件的数量在一个目录中,您可以使用gridfs存储尽可能多的文件需要。

>When you want to keep your files and metadata automatically synced and deployed across a number of systems and facilities. When using geographically distributed replica sets MongoDB can distribute files and their metadata automatically to a number of mongod instances and facilities.
>
* 自动备份

>When you want to access information from portions of large files without having to load whole files into memory, you can use GridFS to recall sections of files without reading the entire file into memory.
>
* 访问大文件，而不想一次把整个文件加载到内存中。

>Do not use GridFS if you need to update the content of the entire file atomically. As an alternative you can store multiple versions of each file and specify the current version of the file in the metadata. You can update the metadata field that indicates “latest” status in an atomic update after uploading the new version of the file, and later remove previous versions if needed.

>Furthermore, if your files are all smaller the 16 MB BSON Document Size limit, consider storing the file manually within a single document. You may use the BinData data type to store the binary data. See your drivers documentation for details on using BinData. 
>
* 如果你的文件<16M可以直接使用document存储，使用的数据类型是Bindata

-----
* [GridFS Reference](http://docs.mongodb.org/manual/reference/gridfs/)
* GridFS Index 
>GridFS uses a unique, compound index on the chunks collection for the files_id and n fields. The files_id field contains the _id of the chunk’s “parent” document. The n field contains the sequence number of the chunk. GridFS numbers all chunks, starting with 0. For descriptions of the documents and fields in the chunks collection, see GridFS Reference.

>The GridFS index allows efficient retrieval (高效检索)of chunks using the files_id and n values, as shown in the following example:`cursor = db.fs.chunks.find({files_id: myFileID}).sort({n:1})`;

------------------------
mongodb 分布式文件系统，主从复制集，分片系统的部署

54 ：主从热备
55 ：主从热备